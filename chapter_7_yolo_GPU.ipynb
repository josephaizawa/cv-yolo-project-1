{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f738a9f3-dbcb-458d-a88c-1c58cbc189ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 13 persons, 4 bicycles, 158.6ms\n",
      "Speed: 0.0ms preprocess, 158.6ms inference, 5.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 12 persons, 5 bicycles, 1 handbag, 180.5ms\n",
      "Speed: 0.0ms preprocess, 180.5ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 11 persons, 5 bicycles, 1 handbag, 163.3ms\n",
      "Speed: 0.0ms preprocess, 163.3ms inference, 5.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 11 persons, 3 bicycles, 1 handbag, 165.0ms\n",
      "Speed: 0.0ms preprocess, 165.0ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 10 persons, 3 bicycles, 163.7ms\n",
      "Speed: 0.0ms preprocess, 163.7ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 12 persons, 4 bicycles, 1 handbag, 165.3ms\n",
      "Speed: 0.0ms preprocess, 165.3ms inference, 5.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 13 persons, 5 bicycles, 156.5ms\n",
      "Speed: 0.0ms preprocess, 156.5ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 10 persons, 3 bicycles, 174.3ms\n",
      "Speed: 0.0ms preprocess, 174.3ms inference, 7.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 11 persons, 4 bicycles, 158.4ms\n",
      "Speed: 0.0ms preprocess, 158.4ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 11 persons, 4 bicycles, 161.5ms\n",
      "Speed: 0.0ms preprocess, 161.5ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 11 persons, 1 bicycle, 1 handbag, 156.9ms\n",
      "Speed: 0.0ms preprocess, 156.9ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 11 persons, 1 bicycle, 162.6ms\n",
      "Speed: 0.0ms preprocess, 162.6ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 13 persons, 1 bicycle, 158.1ms\n",
      "Speed: 0.0ms preprocess, 158.1ms inference, 5.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 13 persons, 1 bicycle, 159.9ms\n",
      "Speed: 0.0ms preprocess, 159.9ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 11 persons, 1 bicycle, 1 handbag, 157.0ms\n",
      "Speed: 0.0ms preprocess, 157.0ms inference, 5.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 10 persons, 1 bicycle, 1 handbag, 161.6ms\n",
      "Speed: 0.0ms preprocess, 161.6ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 11 persons, 2 bicycles, 158.4ms\n",
      "Speed: 0.0ms preprocess, 158.4ms inference, 5.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 11 persons, 2 bicycles, 1 handbag, 1 vase, 159.9ms\n",
      "Speed: 0.0ms preprocess, 159.9ms inference, 5.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 11 persons, 1 bicycle, 169.0ms\n",
      "Speed: 0.0ms preprocess, 169.0ms inference, 5.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 8 persons, 2 bicycles, 1 handbag, 161.2ms\n",
      "Speed: 0.0ms preprocess, 161.2ms inference, 6.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 9 persons, 1 bicycle, 162.7ms\n",
      "Speed: 0.0ms preprocess, 162.7ms inference, 5.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 9 persons, 2 bicycles, 172.2ms\n",
      "Speed: 0.0ms preprocess, 172.2ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 10 persons, 2 bicycles, 165.0ms\n",
      "Speed: 0.0ms preprocess, 165.0ms inference, 5.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 10 persons, 1 bicycle, 163.0ms\n",
      "Speed: 0.0ms preprocess, 163.0ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 6 persons, 2 bicycles, 160.4ms\n",
      "Speed: 0.0ms preprocess, 160.4ms inference, 5.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 8 persons, 3 bicycles, 164.4ms\n",
      "Speed: 0.0ms preprocess, 164.4ms inference, 5.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 8 persons, 1 bicycle, 158.1ms\n",
      "Speed: 0.0ms preprocess, 158.1ms inference, 5.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 8 persons, 1 bicycle, 161.3ms\n",
      "Speed: 0.0ms preprocess, 161.3ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 7 persons, 1 bicycle, 2 handbags, 159.8ms\n",
      "Speed: 0.0ms preprocess, 159.8ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 8 persons, 1 bicycle, 160.3ms\n",
      "Speed: 0.0ms preprocess, 160.3ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 9 persons, 1 bicycle, 156.0ms\n",
      "Speed: 0.0ms preprocess, 156.0ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 10 persons, 1 bicycle, 170.7ms\n",
      "Speed: 0.0ms preprocess, 170.7ms inference, 7.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 7 persons, 1 bicycle, 158.2ms\n",
      "Speed: 0.0ms preprocess, 158.2ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 9 persons, 1 bicycle, 1 elephant, 161.1ms\n",
      "Speed: 0.0ms preprocess, 161.1ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 9 persons, 1 bicycle, 155.7ms\n",
      "Speed: 0.0ms preprocess, 155.7ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 10 persons, 1 bicycle, 160.9ms\n",
      "Speed: 0.0ms preprocess, 160.9ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 12 persons, 2 bicycles, 1 traffic light, 169.9ms\n",
      "Speed: 0.0ms preprocess, 169.9ms inference, 5.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 12 persons, 1 bicycle, 1 handbag, 170.3ms\n",
      "Speed: 0.0ms preprocess, 170.3ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 10 persons, 1 bicycle, 168.3ms\n",
      "Speed: 0.0ms preprocess, 168.3ms inference, 5.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 12 persons, 1 bicycle, 1 car, 163.0ms\n",
      "Speed: 0.0ms preprocess, 163.0ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 8 persons, 2 bicycles, 159.0ms\n",
      "Speed: 0.0ms preprocess, 159.0ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 10 persons, 1 bicycle, 1 elephant, 167.7ms\n",
      "Speed: 0.0ms preprocess, 167.7ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 9 persons, 1 bicycle, 157.5ms\n",
      "Speed: 0.0ms preprocess, 157.5ms inference, 5.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 8 persons, 2 bicycles, 1 elephant, 161.2ms\n",
      "Speed: 0.0ms preprocess, 161.2ms inference, 5.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 7 persons, 3 bicycles, 1 traffic light, 156.2ms\n",
      "Speed: 0.0ms preprocess, 156.2ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 10 persons, 3 bicycles, 1 car, 1 traffic light, 157.1ms\n",
      "Speed: 0.0ms preprocess, 157.1ms inference, 5.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 9 persons, 3 bicycles, 1 traffic light, 158.4ms\n",
      "Speed: 0.0ms preprocess, 158.4ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 8 persons, 3 bicycles, 1 car, 161.7ms\n",
      "Speed: 0.0ms preprocess, 161.7ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 11 persons, 3 bicycles, 1 car, 157.2ms\n",
      "Speed: 0.0ms preprocess, 157.2ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 8 persons, 3 bicycles, 193.6ms\n",
      "Speed: 0.0ms preprocess, 193.6ms inference, 6.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 8 persons, 3 bicycles, 1 traffic light, 1 elephant, 194.0ms\n",
      "Speed: 0.0ms preprocess, 194.0ms inference, 8.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 10 persons, 3 bicycles, 1 traffic light, 193.4ms\n",
      "Speed: 0.0ms preprocess, 193.4ms inference, 6.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 9 persons, 3 bicycles, 1 traffic light, 170.9ms\n",
      "Speed: 0.0ms preprocess, 170.9ms inference, 7.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 9 persons, 3 bicycles, 2 handbags, 180.3ms\n",
      "Speed: 0.0ms preprocess, 180.3ms inference, 7.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 9 persons, 3 bicycles, 192.9ms\n",
      "Speed: 0.0ms preprocess, 192.9ms inference, 7.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 8 persons, 3 bicycles, 1 traffic light, 189.4ms\n",
      "Speed: 0.0ms preprocess, 189.4ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 8 persons, 3 bicycles, 1 car, 1 traffic light, 177.5ms\n",
      "Speed: 0.0ms preprocess, 177.5ms inference, 6.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 9 persons, 3 bicycles, 170.8ms\n",
      "Speed: 0.0ms preprocess, 170.8ms inference, 5.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 8 persons, 3 bicycles, 177.3ms\n",
      "Speed: 0.0ms preprocess, 177.3ms inference, 7.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 10 persons, 2 bicycles, 2 handbags, 162.5ms\n",
      "Speed: 0.0ms preprocess, 162.5ms inference, 5.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 9 persons, 1 bicycle, 1 traffic light, 163.1ms\n",
      "Speed: 0.0ms preprocess, 163.1ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 13 persons, 2 bicycles, 162.8ms\n",
      "Speed: 0.0ms preprocess, 162.8ms inference, 6.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 10 persons, 1 bicycle, 1 car, 173.3ms\n",
      "Speed: 0.0ms preprocess, 173.3ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 8 persons, 1 bicycle, 158.6ms\n",
      "Speed: 0.0ms preprocess, 158.6ms inference, 7.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 8 persons, 1 bicycle, 169.8ms\n",
      "Speed: 0.0ms preprocess, 169.8ms inference, 6.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 8 persons, 2 bicycles, 1 traffic light, 181.5ms\n",
      "Speed: 0.0ms preprocess, 181.5ms inference, 6.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import cv2\n",
    "import cvzone\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "model = YOLO(\"yolo-weights/yolov8n.pt\")\n",
    "# device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "# model.to(device)\n",
    "\n",
    "# cap =  cv2.VideoCapture(0) # For Webcam\n",
    "cap =  cv2.VideoCapture(\"resources/yolo/bikes.mp4\") # For Video\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "# Resize the image to ensure dimensions are divisible by 32\n",
    "def resize_image(img, new_size):\n",
    "    return cv2.resize(img, new_size)\n",
    "\n",
    "# Convert the image to a tensor and normalize\n",
    "def preprocess_image(img):\n",
    "    # Resize image\n",
    "    img_resized = resize_image(img, (640, 640))\n",
    "\n",
    "    # Convert to tensor and normalize\n",
    "    img_tensor = torch.from_numpy(img_resized).permute(2, 0, 1).float() / 255.0\n",
    "\n",
    "    # Add batch dimension\n",
    "    img_tensor = img_tensor.unsqueeze(0)\n",
    "    \n",
    "    return img_tensor\n",
    "\n",
    "\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ]\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    results = model(img,stream=True)\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        for box in boxes:\n",
    "            # Bounding Box\n",
    "            # OpenCV cv2\n",
    "            # x1,y1,x2,y2 = box.xyxy[0]\n",
    "            # x1,y1,x2,y2 = int(x1),int(y1),int(x2),int(y2)\n",
    "            # cv2.rectangle(img,(x1,y1),(x2,y2),(255,0,255),3)\n",
    "            \n",
    "            # cvzone\n",
    "            x1,y1,x2,y2 = box.xyxy[0]\n",
    "            x1,y1,x2,y2 = int(x1),int(y1),int(x2),int(y2)\n",
    "            w,h = x2-x1,y2-y1\n",
    "            cvzone.cornerRect(img,(x1,y1,w,h))\n",
    "            #Confidence\n",
    "            conf = math.ceil(box.conf[0]*100)/100\n",
    "\n",
    "            #Class Name\n",
    "            cls = int(box.cls[0])\n",
    "\n",
    "            cvzone.putTextRect(img,f'{classNames[cls]} {conf}',(max(0,x1),max(35,y1)),scale=1,thickness=1)\n",
    "    \n",
    "    cv2.imshow(\"Image\",img)\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bac573-ae61-42a8-83a4-66afa7dee448",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd36706-8163-42b5-b885-44eb15835882",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
